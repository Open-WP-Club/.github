name: Track Weekly Repository Growth & Traffic

on:
  schedule:
    # Run every Sunday at 2 AM UTC to capture the previous week
    - cron: '0 2 * * 0'
  workflow_dispatch: # Allow manual triggering

jobs:
  track-growth:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.WORKFLOW_TOKEN || github.token }}
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Create package.json and install dependencies
      run: |
        cat > package.json << 'EOF'
        {
          "name": "github-traffic-tracker",
          "version": "1.0.0",
          "description": "Track GitHub organization traffic (clones and views)",
          "main": "track-downloads.js",
          "dependencies": {
            "@octokit/rest": "^20.0.0",
            "csv-writer": "^1.6.0",
            "csv-parser": "^3.0.0"
          }
        }
        EOF
        npm install
        
    - name: Create traffic tracking script
      run: |
        cat > track-downloads.js << 'EOF'
        /*
         * GitHub Repository Tracker
         * 
         * This script tracks repository growth metrics and attempts to get traffic data.
         * 
         * TRAFFIC DATA PERMISSION NOTE:
         * The default GITHUB_TOKEN doesn't have permission to access traffic data.
         * To enable traffic tracking, you need to:
         * 
         * 1. Create a Personal Access Token with 'repo' scope
         * 2. Add it as a repository secret named 'TRAFFIC_TOKEN'
         * 3. Update the workflow to use: token: ${{ secrets.TRAFFIC_TOKEN }}
         * 
         * Without elevated permissions, this script will still track:
         * - Stars, forks, watchers, size, issues
         * - Repository metadata and growth over time
         */
        
        const { Octokit } = require('@octokit/rest');
        const createCsvWriter = require('csv-writer').createObjectCsvWriter;
        const csv = require('csv-parser');
        const fs = require('fs');

        const octokit = new Octokit({
          auth: process.env.GITHUB_TOKEN,
        });

        const CSV_FILE = 'downloads.csv';
        const ORG_NAME = process.env.GITHUB_REPOSITORY.split('/')[0];

        // Get the current week's date range (Sunday to Saturday)
        function getCurrentWeekRange() {
          const now = new Date();
          const currentDay = now.getDay(); // 0 = Sunday, 1 = Monday, etc.
          
          // Calculate the start of the current week (Sunday)
          const weekStart = new Date(now);
          weekStart.setDate(now.getDate() - currentDay);
          weekStart.setHours(0, 0, 0, 0);
          
          // Calculate the end of the current week (Saturday)
          const weekEnd = new Date(weekStart);
          weekEnd.setDate(weekStart.getDate() + 6);
          weekEnd.setHours(23, 59, 59, 999);
          
          return {
            start: weekStart,
            end: weekEnd,
            weekId: `${weekStart.getFullYear()}-W${Math.ceil(weekStart.getDate() / 7)}`
          };
        }

        async function getAllRepos() {
          const repos = [];
          let page = 1;
          let hasNext = true;

          while (hasNext) {
            try {
              const response = await octokit.rest.repos.listForOrg({
                org: ORG_NAME,
                type: 'all',
                per_page: 100,
                page: page,
              });

              repos.push(...response.data);
              
              hasNext = response.data.length === 100;
              page++;
              
              console.log(`Fetched page ${page - 1}, got ${response.data.length} repos`);
            } catch (error) {
              console.error(`Error fetching repos page ${page}:`, error.message);
              break;
            }
          }

          return repos;
        }

        async function getRepoGrowthData(repo) {
          try {
            // This data is accessible with standard GITHUB_TOKEN
            const repoData = {
              stars: repo.stargazers_count,
              forks: repo.forks_count,
              watchers: repo.watchers_count,
              size: repo.size,
              open_issues: repo.open_issues_count,
              language: repo.language || 'None',
              created_at: repo.created_at,
              updated_at: repo.updated_at,
              pushed_at: repo.pushed_at,
              private: repo.private,
              archived: repo.archived,
              disabled: repo.disabled
            };

            // Try to get traffic data if permissions allow
            let trafficData = {
              clones: { count: 0, uniques: 0 },
              views: { count: 0, uniques: 0 },
              referrers: []
            };

            try {
              const cloneResponse = await octokit.rest.repos.getClones({
                owner: repo.owner.login,
                repo: repo.name,
                per: 'week'
              });
              trafficData.clones = cloneResponse.data;
            } catch (error) {
              console.log(`Traffic data not accessible for ${repo.name} (requires elevated permissions)`);
            }

            try {
              const viewResponse = await octokit.rest.repos.getViews({
                owner: repo.owner.login,
                repo: repo.name,
                per: 'week'
              });
              trafficData.views = viewResponse.data;
            } catch (error) {
              // Expected - traffic data requires special permissions
            }

            return { repoData, trafficData };
          } catch (error) {
            console.error(`Error fetching data for ${repo.name}:`, error.message);
            return { 
              repoData: {
                stars: 0, forks: 0, watchers: 0, size: 0, open_issues: 0,
                language: 'Unknown', created_at: '', updated_at: '', pushed_at: '',
                private: false, archived: false, disabled: false
              },
              trafficData: {
                clones: { count: 0, uniques: 0 },
                views: { count: 0, uniques: 0 },
                referrers: []
              }
            };
          }
        }

        async function weekAlreadyExists(weekId) {
          if (!fs.existsSync(CSV_FILE)) {
            return false;
          }
          
          return new Promise((resolve, reject) => {
            let found = false;
            fs.createReadStream(CSV_FILE)
              .pipe(csv())
              .on('data', (row) => {
                if (row.week_id === weekId) {
                  found = true;
                }
              })
              .on('end', () => {
                resolve(found);
              })
              .on('error', reject);
          });
        }

        async function main() {
          try {
            const weekRange = getCurrentWeekRange();
            console.log(`Tracking traffic for week: ${weekRange.weekId}`);
            console.log(`Week range: ${weekRange.start.toISOString()} to ${weekRange.end.toISOString()}`);
            
            // Check if this week's data already exists
            const weekExists = await weekAlreadyExists(weekRange.weekId);
            if (weekExists) {
              console.log(`Data for week ${weekRange.weekId} already exists. Skipping...`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=true\n`);
              return;
            }
            
            console.log(`Tracking traffic for organization: ${ORG_NAME}`);
            
            // Get all repositories in the organization
            const allRepos = await getAllRepos();
            console.log(`Total repositories found: ${allRepos.length}`);
            
            // Track growth and traffic data for each repo
            const allData = [];
            let totalOrgClones = 0;
            let totalOrgViews = 0;
            let totalOrgStars = 0;
            let totalOrgForks = 0;
            let reposWithTraffic = 0;
            
            for (const repo of allRepos) {
              console.log(`Processing ${repo.name}...`);
              const { repoData, trafficData } = await getRepoGrowthData(repo);
              
              const repoClones = trafficData.clones.count || 0;
              const repoViews = trafficData.views.count || 0;
              
              // Always add repo data (even if no traffic data)
              totalOrgClones += repoClones;
              totalOrgViews += repoViews;
              totalOrgStars += repoData.stars;
              totalOrgForks += repoData.forks;
              
              if (repoClones > 0 || repoViews > 0) {
                reposWithTraffic++;
              }
              
              // Add repo summary row
              allData.push({
                week_id: weekRange.weekId,
                week_start: weekRange.start.toISOString(),
                week_end: weekRange.end.toISOString(),
                recorded_date: new Date().toISOString(),
                repo_name: repo.name,
                repo_full_name: repo.full_name,
                entry_type: 'REPO_SUMMARY',
                clone_count: repoClones,
                unique_clones: trafficData.clones.uniques || 0,
                view_count: repoViews,
                unique_views: trafficData.views.uniques || 0,
                top_referrer: trafficData.referrers.length > 0 ? trafficData.referrers[0].referrer : '',
                top_referrer_count: trafficData.referrers.length > 0 ? trafficData.referrers[0].count : 0,
                repo_stars: repoData.stars,
                repo_forks: repoData.forks,
                repo_watchers: repoData.watchers,
                repo_language: repoData.language,
                repo_private: repoData.private,
                repo_size: repoData.size,
                repo_open_issues: repoData.open_issues,
                repo_created_at: repoData.created_at,
                repo_updated_at: repoData.updated_at,
                repo_pushed_at: repoData.pushed_at,
                specific_date: '',
                daily_clones: '',
                daily_views: ''
              });
              
              // Small delay to respect rate limits
              await new Promise(resolve => setTimeout(resolve, 200));
            }
            
            console.log(`Total repositories processed: ${allRepos.length}`);
            console.log(`Repositories with traffic data: ${reposWithTraffic}`);
            console.log(`Total organization clones: ${totalOrgClones}`);
            console.log(`Total organization views: ${totalOrgViews}`);
            console.log(`Total organization stars: ${totalOrgStars}`);
            console.log(`Total organization forks: ${totalOrgForks}`);
            console.log(`Total records to add: ${allData.length}`);
            
            // Always create the CSV file, even if no traffic data
            const csvWriter = createCsvWriter({
              path: CSV_FILE,
              header: [
                { id: 'week_id', title: 'Week ID' },
                { id: 'week_start', title: 'Week Start' },
                { id: 'week_end', title: 'Week End' },
                { id: 'recorded_date', title: 'Recorded Date' },
                { id: 'repo_name', title: 'Repository Name' },
                { id: 'repo_full_name', title: 'Repository Full Name' },
                { id: 'entry_type', title: 'Entry Type' },
                { id: 'clone_count', title: 'Total Clones' },
                { id: 'unique_clones', title: 'Unique Clones' },
                { id: 'view_count', title: 'Total Views' },
                { id: 'unique_views', title: 'Unique Views' },
                { id: 'top_referrer', title: 'Top Referrer' },
                { id: 'top_referrer_count', title: 'Top Referrer Count' },
                { id: 'repo_stars', title: 'Repository Stars' },
                { id: 'repo_forks', title: 'Repository Forks' },
                { id: 'repo_watchers', title: 'Repository Watchers' },
                { id: 'repo_language', title: 'Primary Language' },
                { id: 'repo_private', title: 'Is Private' },
                { id: 'repo_size', title: 'Repository Size (KB)' },
                { id: 'repo_open_issues', title: 'Open Issues' },
                { id: 'repo_created_at', title: 'Repository Created' },
                { id: 'repo_updated_at', title: 'Repository Updated' },
                { id: 'repo_pushed_at', title: 'Last Push' },
                { id: 'specific_date', title: 'Specific Date' },
                { id: 'daily_clones', title: 'Daily Clones' },
                { id: 'daily_views', title: 'Daily Views' }
              ],
              append: fs.existsSync(CSV_FILE)
            });
            
            // Write data to CSV
            if (allData.length > 0) {
              await csvWriter.writeRecords(allData);
              console.log(`Successfully added ${allData.length} records for week ${weekRange.weekId} to ${CSV_FILE}`);
            } else {
              // Create empty CSV with headers if no data
              await csvWriter.writeRecords([]);
              console.log(`Created empty CSV file for week ${weekRange.weekId}`);
            }
            
            // Set outputs using environment file
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `week_id=${weekRange.weekId}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_clones=${totalOrgClones}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_views=${totalOrgViews}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_stars=${totalOrgStars}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_forks=${totalOrgForks}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `repos_with_traffic=${reposWithTraffic}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_repos=${allRepos.length}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=false\n`);
            
          } catch (error) {
            console.error('Error:', error);
            process.exit(1);
          }
        }

        main();
        EOF
        
    - name: Run traffic tracking
      id: track
      env:
        GITHUB_TOKEN: ${{ secrets.WORKFLOW_TOKEN || github.token }}
      run: node track-downloads.js
      
    - name: Commit and push changes
      if: steps.track.outputs.skipped != 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.WORKFLOW_TOKEN || github.token }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [[ -n $(git status --porcelain) ]]; then
          git add downloads.csv
          git commit -m "📊 Weekly repo tracking: ${{ steps.track.outputs.week_id }} - ${{ steps.track.outputs.total_repos }} repos, ${{ steps.track.outputs.total_stars }} stars, ${{ steps.track.outputs.total_forks }} forks, ${{ steps.track.outputs.total_clones }} clones, ${{ steps.track.outputs.total_views }} views"
          git push
          echo "Changes committed and pushed"
        else
          echo "No changes to commit"
        fi
        
    - name: Skip notification
      if: steps.track.outputs.skipped == 'true'
      run: echo "Skipped - data for this week already exists"
        
    - name: Upload CSV as artifact
      uses: actions/upload-artifact@v4
      with:
        name: weekly-traffic-csv
        path: downloads.csv
        retention-days: 90