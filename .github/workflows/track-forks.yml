name: Track Weekly Repository Growth & Traffic

on:
  schedule:
    # Run every Sunday at 2 AM UTC to capture the previous week
    - cron: '0 2 * * 0'
  workflow_dispatch: # Allow manual triggering

jobs:
  track-growth:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.WORKFLOW_TOKEN || github.token }}
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Create package.json and install dependencies
      run: |
        cat > package.json << 'EOF'
        {
          "name": "github-traffic-tracker",
          "version": "1.0.0",
          "description": "Track GitHub organization traffic (clones and views)",
          "main": "track-downloads.js",
          "dependencies": {
            "@octokit/rest": "^20.0.0",
            "csv-writer": "^1.6.0",
            "csv-parser": "^3.0.0"
          }
        }
        EOF
        npm install
        
    - name: Create traffic tracking script
      run: |
        cat > track-downloads.js << 'EOF'
        /*
         * GitHub Repository Tracker
         * 
         * This script tracks repository growth metrics and attempts to get traffic data.
         * 
         * TRAFFIC DATA PERMISSION NOTE:
         * The default GITHUB_TOKEN doesn't have permission to access traffic data.
         * To enable traffic tracking, you need to:
         * 
         * 1. Create a Personal Access Token with 'repo' scope
         * 2. Add it as a repository secret named 'WORKFLOW_TOKEN'
         * 3. Update the workflow to use: token: ${{ secrets.WORKFLOW_TOKEN }}
         * 
         * CSV COLUMNS EXPLANATION:
         * 
         * TIMING & IDENTIFICATION:
         * â€¢ Week ID: Week identifier (e.g., "2025-W25")
         * â€¢ Week Start: Start date of the tracking week (ISO format)
         * â€¢ Week End: End date of the tracking week (ISO format)
         * â€¢ Recorded Date: When this data was captured (ISO format)
         * 
         * REPOSITORY IDENTIFICATION:
         * â€¢ Repository Name: Short name of the repo (e.g., "wp-rank-math-automation")
         * â€¢ Repository Full Name: Full name with org (e.g., "Open-WP-Club/wp-rank-math-automation")
         * â€¢ Entry Type: Type of data row ("REPO_SUMMARY", "DAILY_CLONES", "DAILY_VIEWS")
         * 
         * TRAFFIC DATA (requires elevated permissions):
         * â€¢ Total Clones: Number of git clone operations in the week
         * â€¢ Unique Clones: Number of unique users who cloned the repo
         * â€¢ Total Views: Number of repository page views in the week
         * â€¢ Unique Views: Number of unique visitors to the repo page
         * â€¢ Top Referrer: Main source of traffic (e.g., "github.com", "google.com")
         * â€¢ Top Referrer Count: Number of visits from the top referrer
         * 
         * REPOSITORY METRICS (always available):
         * â€¢ Repository Stars: Current number of stars/favorites
         * â€¢ Repository Forks: Current number of forks
         * â€¢ Repository Watchers: Current number of watchers/subscribers
         * â€¢ Primary Language: Main programming language (e.g., "PHP", "JavaScript")
         * â€¢ Is Private: Whether the repository is private (true/false)
         * â€¢ Repository Size (KB): Size of the repository in kilobytes
         * â€¢ Open Issues: Current number of open issues
         * 
         * REPOSITORY DATES:
         * â€¢ Repository Created: When the repository was originally created
         * â€¢ Repository Updated: When repository metadata was last updated
         * â€¢ Last Push: When code was last committed/pushed
         * 
         * DAILY BREAKDOWN (for detailed analysis):
         * â€¢ Specific Date: Date for daily breakdown entries
         * â€¢ Daily Clones: Clone count for a specific day
         * â€¢ Daily Views: View count for a specific day
         * 
         * ENTRY TYPES:
         * â€¢ REPO_SUMMARY: Weekly totals for each repository
         * â€¢ DAILY_CLONES: Day-by-day clone breakdown (if traffic data available)
         * â€¢ DAILY_VIEWS: Day-by-day view breakdown (if traffic data available)
         */
        
        const { Octokit } = require('@octokit/rest');
        const createCsvWriter = require('csv-writer').createObjectCsvWriter;
        const csv = require('csv-parser');
        const fs = require('fs');

        const octokit = new Octokit({
          auth: process.env.GITHUB_TOKEN,
        });

        const CSV_FILE = 'downloads.csv';
        const STATS_FILE = 'stats.csv';
        const ORG_NAME = process.env.GITHUB_REPOSITORY.split('/')[0];

        // Get the current week's date range (Sunday to Saturday)
        function getCurrentWeekRange() {
          const now = new Date();
          const currentDay = now.getDay(); // 0 = Sunday, 1 = Monday, etc.
          
          // Calculate the start of the current week (Sunday)
          const weekStart = new Date(now);
          weekStart.setDate(now.getDate() - currentDay);
          weekStart.setHours(0, 0, 0, 0);
          
          // Calculate the end of the current week (Saturday)
          const weekEnd = new Date(weekStart);
          weekEnd.setDate(weekStart.getDate() + 6);
          weekEnd.setHours(23, 59, 59, 999);
          
          return {
            start: weekStart,
            end: weekEnd,
            weekId: `${weekStart.getFullYear()}-W${Math.ceil(weekStart.getDate() / 7)}`
          };
        }

        async function getAllRepos() {
          const repos = [];
          let page = 1;
          let hasNext = true;

          while (hasNext) {
            try {
              const response = await octokit.rest.repos.listForOrg({
                org: ORG_NAME,
                type: 'all',
                per_page: 100,
                page: page,
              });

              repos.push(...response.data);
              
              hasNext = response.data.length === 100;
              page++;
              
              console.log(`Fetched page ${page - 1}, got ${response.data.length} repos`);
            } catch (error) {
              console.error(`Error fetching repos page ${page}:`, error.message);
              break;
            }
          }

          return repos;
        }

        async function getRepoGrowthData(repo) {
          try {
            // This data is accessible with standard GITHUB_TOKEN
            const repoData = {
              stars: repo.stargazers_count,
              forks: repo.forks_count,
              watchers: repo.watchers_count,
              size: repo.size,
              open_issues: repo.open_issues_count,
              language: repo.language || 'None',
              created_at: repo.created_at,
              updated_at: repo.updated_at,
              pushed_at: repo.pushed_at,
              private: repo.private,
              archived: repo.archived,
              disabled: repo.disabled
            };

            // Try to get traffic data if permissions allow
            let trafficData = {
              clones: { count: 0, uniques: 0 },
              views: { count: 0, uniques: 0 },
              referrers: []
            };

            try {
              const cloneResponse = await octokit.rest.repos.getClones({
                owner: repo.owner.login,
                repo: repo.name,
                per: 'week'
              });
              trafficData.clones = cloneResponse.data;
            } catch (error) {
              console.log(`Traffic data not accessible for ${repo.name} (requires elevated permissions)`);
            }

            try {
              const viewResponse = await octokit.rest.repos.getViews({
                owner: repo.owner.login,
                repo: repo.name,
                per: 'week'
              });
              trafficData.views = viewResponse.data;
            } catch (error) {
              // Expected - traffic data requires special permissions
            }

            return { repoData, trafficData };
          } catch (error) {
            console.error(`Error fetching data for ${repo.name}:`, error.message);
            return { 
              repoData: {
                stars: 0, forks: 0, watchers: 0, size: 0, open_issues: 0,
                language: 'Unknown', created_at: '', updated_at: '', pushed_at: '',
                private: false, archived: false, disabled: false
              },
              trafficData: {
                clones: { count: 0, uniques: 0 },
                views: { count: 0, uniques: 0 },
                referrers: []
              }
            };
          }
        }

        async function weekAlreadyExists(weekId) {
          if (!fs.existsSync(CSV_FILE)) {
            return false;
          }
          
          return new Promise((resolve, reject) => {
            let found = false;
            fs.createReadStream(CSV_FILE)
              .pipe(csv())
              .on('data', (row) => {
                if (row.week_id === weekId) {
                  found = true;
                }
              })
              .on('end', () => {
                resolve(found);
              })
              .on('error', reject);
          });
        }

        async function statsWeekAlreadyExists(weekStart) {
          if (!fs.existsSync(STATS_FILE)) {
            return false;
          }
          
          return new Promise((resolve, reject) => {
            let found = false;
            fs.createReadStream(STATS_FILE)
              .pipe(csv())
              .on('data', (row) => {
                if (row.week_start === weekStart) {
                  found = true;
                }
              })
              .on('end', () => {
                resolve(found);
              })
              .on('error', reject);
          });
        }

        async function main() {
          try {
            const weekRange = getCurrentWeekRange();
            console.log(`Tracking traffic for week: ${weekRange.weekId}`);
            console.log(`Week range: ${weekRange.start.toISOString()} to ${weekRange.end.toISOString()}`);
            
            // Check if this week's data already exists in both files
            const weekExists = await weekAlreadyExists(weekRange.weekId);
            const statsWeekExists = await statsWeekAlreadyExists(weekRange.start.toISOString());
            
            if (weekExists && statsWeekExists) {
              console.log(`Data for week ${weekRange.weekId} already exists in both files. Skipping...`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=true\n`);
              return;
            }
            
            console.log(`Tracking traffic for organization: ${ORG_NAME}`);
            
            // Log CSV column structure for reference
            console.log('\nðŸ“Š FILE MANAGEMENT:');
            console.log('â”Œâ”€ downloads.csv: Detailed repository data (appends new rows each week)');
            console.log('â””â”€ stats.csv: Weekly organization summaries (appends new rows each week for website trends)\n');
            
            console.log('ðŸ“ˆ DOWNLOADS.CSV COLUMNS:');
            console.log('â”Œâ”€ TIMING: Week ID, Week Start/End, Recorded Date');
            console.log('â”œâ”€ REPO ID: Repository Name, Full Name, Entry Type');
            console.log('â”œâ”€ TRAFFIC: Clones, Views, Unique Visitors, Top Referrer (if permissions allow)');
            console.log('â”œâ”€ METRICS: Stars, Forks, Watchers, Language, Size, Issues');
            console.log('â”œâ”€ DATES: Created, Updated, Last Push');
            console.log('â””â”€ DAILY: Specific Date, Daily Clones/Views (for detailed entries)');
            
            console.log('\nðŸ“Š STATS.CSV COLUMNS (Perfect for Website Charts):');
            console.log('â”Œâ”€ TIMING: Week Start/End, Recorded Date');
            console.log('â”œâ”€ TRAFFIC: Total Clones, Views, Unique Visitors');
            console.log('â”œâ”€ GROWTH: Total Stars, Forks, Watchers');
            console.log('â”œâ”€ BREAKDOWN: Private/Public Repos, Repos With Traffic, Repository Size, Open Issues');
            console.log('â””â”€ HIGHLIGHTS: Most Starred/Forked Repository\n');
            
            // Get all repositories in the organization
            const allRepos = await getAllRepos();
            console.log(`Total repositories found: ${allRepos.length}`);
            
            // Track growth and traffic data for each repo
            const allData = [];
            const repoDataMap = new Map(); // Store repo data for summary stats
            let totalOrgClones = 0;
            let totalOrgViews = 0;
            let totalOrgStars = 0;
            let totalOrgForks = 0;
            let reposWithTraffic = 0;
            
            for (const repo of allRepos) {
              console.log(`Processing ${repo.name}...`);
              const { repoData, trafficData } = await getRepoGrowthData(repo);
              
              // Store for summary calculations
              repoDataMap.set(repo.name, { repo, repoData, trafficData });
              
              const repoClones = trafficData.clones.count || 0;
              const repoViews = trafficData.views.count || 0;
              
              // Always add repo data (even if no traffic data)
              totalOrgClones += repoClones;
              totalOrgViews += repoViews;
              totalOrgStars += repoData.stars;
              totalOrgForks += repoData.forks;
              
              if (repoClones > 0 || repoViews > 0) {
                reposWithTraffic++;
              }
              
              // Add repo summary row
              allData.push({
                week_id: weekRange.weekId,
                week_start: weekRange.start.toISOString(),
                week_end: weekRange.end.toISOString(),
                recorded_date: new Date().toISOString(),
                repo_name: repo.name,
                repo_full_name: repo.full_name,
                entry_type: 'REPO_SUMMARY',
                clone_count: repoClones,
                unique_clones: trafficData.clones.uniques || 0,
                view_count: repoViews,
                unique_views: trafficData.views.uniques || 0,
                top_referrer: trafficData.referrers.length > 0 ? trafficData.referrers[0].referrer : '',
                top_referrer_count: trafficData.referrers.length > 0 ? trafficData.referrers[0].count : 0,
                repo_stars: repoData.stars,
                repo_forks: repoData.forks,
                repo_watchers: repoData.watchers,
                repo_language: repoData.language,
                repo_private: repoData.private,
                repo_size: repoData.size,
                repo_open_issues: repoData.open_issues,
                repo_created_at: repoData.created_at,
                repo_updated_at: repoData.updated_at,
                repo_pushed_at: repoData.pushed_at,
                specific_date: '',
                daily_clones: '',
                daily_views: ''
              });
              
              // Small delay to respect rate limits
              await new Promise(resolve => setTimeout(resolve, 200));
            }
            
            console.log(`Total repositories processed: ${allRepos.length}`);
            console.log(`Repositories with traffic data: ${reposWithTraffic}`);
            console.log(`Total organization clones: ${totalOrgClones}`);
            console.log(`Total organization views: ${totalOrgViews}`);
            console.log(`Total organization stars: ${totalOrgStars}`);
            console.log(`Total organization forks: ${totalOrgForks}`);
            console.log(`Total records to add: ${allData.length}`);
            
            console.log('\nðŸ“ˆ WEEKLY UPDATE SUMMARY:');
            console.log(`â€¢ downloads.csv: ${!weekExists ? 'âœ… Appended' : 'â­ï¸ Skipped'} ${allData.length} detailed records for week ${weekRange.weekId}`);
            console.log(`â€¢ stats.csv: ${!statsWeekExists ? 'âœ… Appended' : 'â­ï¸ Skipped'} 1 summary row for week ${weekRange.weekId}`);
            console.log(`â€¢ Repository data: âœ… Processed all ${allRepos.length} repositories`);
            console.log(`â€¢ Traffic data: ${reposWithTraffic > 0 ? 'âœ…' : 'âŒ'} Available for ${reposWithTraffic} repositories`);
            console.log(`â€¢ Organization totals: ${totalOrgStars} stars, ${totalOrgForks} forks`);
            if (totalOrgClones > 0 || totalOrgViews > 0) {
              console.log(`â€¢ Weekly traffic: ${totalOrgClones} clones, ${totalOrgViews} views`);
            } else {
              console.log('â€¢ Weekly traffic: Not available (requires WORKFLOW_TOKEN with repo scope)');
            }
            console.log('\nðŸŒ Files ready for website integration!');
            
            // Always append to the detailed CSV file (if not already exists for this week)
            if (!weekExists) {
              // Check if this is the first time creating the downloads file
              const isFirstDownloadsEntry = !fs.existsSync(CSV_FILE);
              
              const csvWriter = createCsvWriter({
                path: CSV_FILE,
                header: [
                  { id: 'week_id', title: 'Week ID' },
                  { id: 'week_start', title: 'Week Start' },
                  { id: 'week_end', title: 'Week End' },
                  { id: 'recorded_date', title: 'Recorded Date' },
                  { id: 'repo_name', title: 'Repository Name' },
                  { id: 'repo_full_name', title: 'Repository Full Name' },
                  { id: 'entry_type', title: 'Entry Type' },
                  { id: 'clone_count', title: 'Total Clones' },
                  { id: 'unique_clones', title: 'Unique Clones' },
                  { id: 'view_count', title: 'Total Views' },
                  { id: 'unique_views', title: 'Unique Views' },
                  { id: 'top_referrer', title: 'Top Referrer' },
                  { id: 'top_referrer_count', title: 'Top Referrer Count' },
                  { id: 'repo_stars', title: 'Repository Stars' },
                  { id: 'repo_forks', title: 'Repository Forks' },
                  { id: 'repo_watchers', title: 'Repository Watchers' },
                  { id: 'repo_language', title: 'Primary Language' },
                  { id: 'repo_private', title: 'Is Private' },
                  { id: 'repo_size', title: 'Repository Size (KB)' },
                  { id: 'repo_open_issues', title: 'Open Issues' },
                  { id: 'repo_created_at', title: 'Repository Created' },
                  { id: 'repo_updated_at', title: 'Repository Updated' },
                  { id: 'repo_pushed_at', title: 'Last Push' },
                  { id: 'specific_date', title: 'Specific Date' },
                  { id: 'daily_clones', title: 'Daily Clones' },
                  { id: 'daily_views', title: 'Daily Views' }
                ],
                append: !isFirstDownloadsEntry  // Only append if file already exists, otherwise write headers
              });
              
              // Append detailed data to downloads.csv
              if (allData.length > 0) {
                await csvWriter.writeRecords(allData);
                console.log(`Successfully appended ${allData.length} detailed records for week ${weekRange.weekId} to ${CSV_FILE}`);
              }
            }
            
            // Always append to the summary stats CSV file (if not already exists for this week)
            if (!statsWeekExists) {
              // Check if this is the first time creating the stats file
              const isFirstStatsEntry = !fs.existsSync(STATS_FILE);
              
              const statsWriter = createCsvWriter({
                path: STATS_FILE,
                header: [
                  { id: 'week_start', title: 'Week Start' },
                  { id: 'week_end', title: 'Week End' },
                  { id: 'recorded_date', title: 'Recorded Date' },
                  { id: 'total_clones', title: 'Total Clones' },
                  { id: 'total_unique_clones', title: 'Total Unique Clones' },
                  { id: 'total_views', title: 'Total Views' },
                  { id: 'total_unique_views', title: 'Total Unique Views' },
                  { id: 'total_stars', title: 'Total Stars' },
                  { id: 'total_forks', title: 'Total Forks' },
                  { id: 'total_watchers', title: 'Total Watchers' },
                  { id: 'repos_with_traffic', title: 'Repos With Traffic Data' },
                  { id: 'total_repo_size_kb', title: 'Total Repository Size (KB)' },
                  { id: 'total_open_issues', title: 'Total Open Issues' },
                  { id: 'private_repos', title: 'Private Repositories' },
                  { id: 'public_repos', title: 'Public Repositories' },
                  { id: 'most_starred_repo', title: 'Most Starred Repository' },
                  { id: 'most_forked_repo', title: 'Most Forked Repository' }
                ],
                append: !isFirstStatsEntry  // Only append if file already exists, otherwise write headers
              });

              // Calculate summary statistics using stored data
              let totalUniqueClones = 0;
              let totalUniqueViews = 0;
              let totalWatchers = 0;
              let totalRepoSize = 0;
              let totalOpenIssues = 0;
              let privateRepos = 0;
              let publicRepos = 0;
              let mostStarredRepo = { name: '', stars: 0 };
              let mostForkedRepo = { name: '', forks: 0 };

              // Process stored repo data for summary stats
              for (const [repoName, { repo, repoData, trafficData }] of repoDataMap) {
                totalUniqueClones += trafficData.clones.uniques || 0;
                totalUniqueViews += trafficData.views.uniques || 0;
                totalWatchers += repoData.watchers;
                totalRepoSize += repoData.size;
                totalOpenIssues += repoData.open_issues;
                
                if (repoData.private) privateRepos++;
                else publicRepos++;
                
                // Track most starred/forked
                if (repoData.stars > mostStarredRepo.stars) {
                  mostStarredRepo = { name: repo.name, stars: repoData.stars };
                }
                if (repoData.forks > mostForkedRepo.forks) {
                  mostForkedRepo = { name: repo.name, forks: repoData.forks };
                }
              }

              const summaryStats = [{
                week_start: weekRange.start.toISOString(),
                week_end: weekRange.end.toISOString(),
                recorded_date: new Date().toISOString(),
                total_clones: totalOrgClones,
                total_unique_clones: totalUniqueClones,
                total_views: totalOrgViews,
                total_unique_views: totalUniqueViews,
                total_stars: totalOrgStars,
                total_forks: totalOrgForks,
                total_watchers: totalWatchers,
                repos_with_traffic: reposWithTraffic,
                total_repo_size_kb: totalRepoSize,
                total_open_issues: totalOpenIssues,
                private_repos: privateRepos,
                public_repos: publicRepos,
                most_starred_repo: mostStarredRepo.name,
                most_forked_repo: mostForkedRepo.name
              }];

              await statsWriter.writeRecords(summaryStats);
              console.log(`Successfully appended summary stats for week ${weekRange.weekId} to ${STATS_FILE}`);
            }
            
            // Set outputs using environment file
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `week_id=${weekRange.weekId}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_clones=${totalOrgClones}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_views=${totalOrgViews}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_stars=${totalOrgStars}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_forks=${totalOrgForks}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `repos_with_traffic=${reposWithTraffic}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_repos=${allRepos.length}\n`);
            fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=false\n`);
            
          } catch (error) {
            console.error('Error:', error);
            process.exit(1);
          }
        }

        main();
        EOF
        
    - name: Run traffic tracking
      id: track
      env:
        GITHUB_TOKEN: ${{ secrets.WORKFLOW_TOKEN || github.token }}
      run: node track-downloads.js
      
    - name: Commit and push changes
      if: steps.track.outputs.skipped != 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.WORKFLOW_TOKEN || github.token }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [[ -n $(git status --porcelain) ]]; then
          git add downloads.csv stats.csv
          git commit -m "ðŸ“Š Weekly repo tracking: ${{ steps.track.outputs.week_id }} - ${{ steps.track.outputs.total_repos }} repos, ${{ steps.track.outputs.total_stars }} stars, ${{ steps.track.outputs.total_forks }} forks, ${{ steps.track.outputs.total_clones }} clones, ${{ steps.track.outputs.total_views }} views"
          git push
          echo "Changes committed and pushed"
        else
          echo "No changes to commit"
        fi
        
    - name: Skip notification
      if: steps.track.outputs.skipped == 'true'
      run: echo "Skipped - data for this week already exists"
        
    - name: Upload CSV files as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: weekly-repo-tracking-csvs
        path: |
          downloads.csv
          stats.csv
        retention-days: 90