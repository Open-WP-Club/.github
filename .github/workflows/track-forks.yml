name: Track Weekly Traffic (Clones & Views)

on:
  schedule:
    # Run every Sunday at 2 AM UTC to capture the previous week
    - cron: '0 2 * * 0'
  workflow_dispatch: # Allow manual triggering

jobs:
  track-traffic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Create package.json and install dependencies
      run: |
        cat > package.json << 'EOF'
        {
          "name": "github-traffic-tracker",
          "version": "1.0.0",
          "description": "Track GitHub organization traffic (clones and views)",
          "main": "track-downloads.js",
          "dependencies": {
            "@octokit/rest": "^20.0.0",
            "csv-writer": "^1.6.0",
            "csv-parser": "^3.0.0"
          }
        }
        EOF
        npm install
        
    - name: Create traffic tracking script
      run: |
        cat > track-downloads.js << 'EOF'
        const { Octokit } = require('@octokit/rest');
        const createCsvWriter = require('csv-writer').createObjectCsvWriter;
        const csv = require('csv-parser');
        const fs = require('fs');

        const octokit = new Octokit({
          auth: process.env.GITHUB_TOKEN,
        });

        const CSV_FILE = 'downloads.csv';
        const ORG_NAME = process.env.GITHUB_REPOSITORY.split('/')[0];

        // Get the current week's date range (Sunday to Saturday)
        function getCurrentWeekRange() {
          const now = new Date();
          const currentDay = now.getDay(); // 0 = Sunday, 1 = Monday, etc.
          
          // Calculate the start of the current week (Sunday)
          const weekStart = new Date(now);
          weekStart.setDate(now.getDate() - currentDay);
          weekStart.setHours(0, 0, 0, 0);
          
          // Calculate the end of the current week (Saturday)
          const weekEnd = new Date(weekStart);
          weekEnd.setDate(weekStart.getDate() + 6);
          weekEnd.setHours(23, 59, 59, 999);
          
          return {
            start: weekStart,
            end: weekEnd,
            weekId: `${weekStart.getFullYear()}-W${Math.ceil(weekStart.getDate() / 7)}`
          };
        }

        async function getAllRepos() {
          const repos = [];
          let page = 1;
          let hasNext = true;

          while (hasNext) {
            try {
              const response = await octokit.rest.repos.listForOrg({
                org: ORG_NAME,
                type: 'all',
                per_page: 100,
                page: page,
              });

              repos.push(...response.data);
              
              hasNext = response.data.length === 100;
              page++;
              
              console.log(`Fetched page ${page - 1}, got ${response.data.length} repos`);
            } catch (error) {
              console.error(`Error fetching repos page ${page}:`, error.message);
              break;
            }
          }

          return repos;
        }

        async function getRepoTrafficData(repo) {
          try {
            // Get clone data (git clone operations)
            const cloneResponse = await octokit.rest.repos.getClones({
              owner: repo.owner.login,
              repo: repo.name,
              per: 'week'
            });

            // Get view data (repository page views)
            const viewResponse = await octokit.rest.repos.getViews({
              owner: repo.owner.login,
              repo: repo.name,
              per: 'week'
            });

            // Get referrer data (where traffic comes from)
            let referrers = [];
            try {
              const referrerResponse = await octokit.rest.repos.getTopReferrers({
                owner: repo.owner.login,
                repo: repo.name
              });
              referrers = referrerResponse.data;
            } catch (error) {
              console.log(`No referrer data for ${repo.name}`);
            }

            return {
              clones: cloneResponse.data,
              views: viewResponse.data,
              referrers: referrers
            };
          } catch (error) {
            console.error(`Error fetching traffic data for ${repo.name}:`, error.message);
            return { 
              clones: { count: 0, uniques: 0, clones: [] },
              views: { count: 0, uniques: 0, views: [] },
              referrers: []
            };
          }
        }

        async function weekAlreadyExists(weekId) {
          if (!fs.existsSync(CSV_FILE)) {
            return false;
          }
          
          return new Promise((resolve, reject) => {
            let found = false;
            fs.createReadStream(CSV_FILE)
              .pipe(csv())
              .on('data', (row) => {
                if (row.week_id === weekId) {
                  found = true;
                }
              })
              .on('end', () => {
                resolve(found);
              })
              .on('error', reject);
          });
        }

        async function main() {
          try {
            const weekRange = getCurrentWeekRange();
            console.log(`Tracking downloads for week: ${weekRange.weekId}`);
            console.log(`Week range: ${weekRange.start.toISOString()} to ${weekRange.end.toISOString()}`);
            
            // Check if this week's data already exists
            const weekExists = await weekAlreadyExists(weekRange.weekId);
            if (weekExists) {
              console.log(`Data for week ${weekRange.weekId} already exists. Skipping...`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=true\n`);
              return;
            }
            
            console.log(`Tracking downloads for organization: ${ORG_NAME}`);
            
            // Get all repositories in the organization
            const allRepos = await getAllRepos();
            console.log(`Total repositories found: ${allRepos.length}`);
            
            // Track traffic data for each repo
            const trafficData = [];
            let totalOrgClones = 0;
            let totalOrgViews = 0;
            let reposWithTraffic = 0;
            
            for (const repo of allRepos) {
              console.log(`Processing ${repo.name}...`);
              const { clones, views, referrers } = await getRepoTrafficData(repo);
              
              const repoClones = clones.count || 0;
              const repoViews = views.count || 0;
              
              if (repoClones > 0 || repoViews > 0) {
                reposWithTraffic++;
                totalOrgClones += repoClones;
                totalOrgViews += repoViews;
                
                // Add summary row for the repo
                trafficData.push({
                  week_id: weekRange.weekId,
                  week_start: weekRange.start.toISOString(),
                  week_end: weekRange.end.toISOString(),
                  recorded_date: new Date().toISOString(),
                  repo_name: repo.name,
                  repo_full_name: repo.full_name,
                  entry_type: 'REPO_SUMMARY',
                  clone_count: repoClones,
                  unique_clones: clones.uniques || 0,
                  view_count: repoViews,
                  unique_views: views.uniques || 0,
                  top_referrer: referrers.length > 0 ? referrers[0].referrer : '',
                  top_referrer_count: referrers.length > 0 ? referrers[0].count : 0,
                  repo_stars: repo.stargazers_count,
                  repo_forks: repo.forks_count,
                  repo_language: repo.language || 'None',
                  repo_private: repo.private,
                  repo_size: repo.size,
                  specific_date: '',
                  daily_clones: '',
                  daily_views: ''
                });
                
                // Add daily breakdown for clones
                if (clones.clones && clones.clones.length > 0) {
                  for (const dailyClone of clones.clones) {
                    trafficData.push({
                      week_id: weekRange.weekId,
                      week_start: weekRange.start.toISOString(),
                      week_end: weekRange.end.toISOString(),
                      recorded_date: new Date().toISOString(),
                      repo_name: repo.name,
                      repo_full_name: repo.full_name,
                      entry_type: 'DAILY_CLONES',
                      clone_count: '',
                      unique_clones: '',
                      view_count: '',
                      unique_views: '',
                      top_referrer: '',
                      top_referrer_count: '',
                      repo_stars: '',
                      repo_forks: '',
                      repo_language: '',
                      repo_private: '',
                      repo_size: '',
                      specific_date: dailyClone.timestamp,
                      daily_clones: dailyClone.count,
                      daily_views: ''
                    });
                  }
                }
                
                // Add daily breakdown for views
                if (views.views && views.views.length > 0) {
                  for (const dailyView of views.views) {
                    trafficData.push({
                      week_id: weekRange.weekId,
                      week_start: weekRange.start.toISOString(),
                      week_end: weekRange.end.toISOString(),
                      recorded_date: new Date().toISOString(),
                      repo_name: repo.name,
                      repo_full_name: repo.full_name,
                      entry_type: 'DAILY_VIEWS',
                      clone_count: '',
                      unique_clones: '',
                      view_count: '',
                      unique_views: '',
                      top_referrer: '',
                      top_referrer_count: '',
                      repo_stars: '',
                      repo_forks: '',
                      repo_language: '',
                      repo_private: '',
                      repo_size: '',
                      specific_date: dailyView.timestamp,
                      daily_clones: '',
                      daily_views: dailyView.count
                    });
                  }
                }
              }
              
              // Small delay to respect rate limits
              await new Promise(resolve => setTimeout(resolve, 200));
            }
            
            console.log(`Repositories with traffic: ${reposWithTraffic}`);
            console.log(`Total organization clones: ${totalOrgClones}`);
            console.log(`Total organization views: ${totalOrgViews}`);
            console.log(`Total records to add: ${trafficData.length}`);
            
            if (trafficData.length > 0) {
              // Setup CSV writer
              const csvWriter = createCsvWriter({
                path: CSV_FILE,
                header: [
                  { id: 'week_id', title: 'Week ID' },
                  { id: 'week_start', title: 'Week Start' },
                  { id: 'week_end', title: 'Week End' },
                  { id: 'recorded_date', title: 'Recorded Date' },
                  { id: 'repo_name', title: 'Repository Name' },
                  { id: 'repo_full_name', title: 'Repository Full Name' },
                  { id: 'entry_type', title: 'Entry Type' },
                  { id: 'clone_count', title: 'Total Clones' },
                  { id: 'unique_clones', title: 'Unique Clones' },
                  { id: 'view_count', title: 'Total Views' },
                  { id: 'unique_views', title: 'Unique Views' },
                  { id: 'top_referrer', title: 'Top Referrer' },
                  { id: 'top_referrer_count', title: 'Top Referrer Count' },
                  { id: 'repo_stars', title: 'Repository Stars' },
                  { id: 'repo_forks', title: 'Repository Forks' },
                  { id: 'repo_language', title: 'Primary Language' },
                  { id: 'repo_private', title: 'Is Private' },
                  { id: 'repo_size', title: 'Repository Size (KB)' },
                  { id: 'specific_date', title: 'Specific Date' },
                  { id: 'daily_clones', title: 'Daily Clones' },
                  { id: 'daily_views', title: 'Daily Views' }
                ],
                append: fs.existsSync(CSV_FILE)
              });
              
              // Write traffic data to CSV
              await csvWriter.writeRecords(trafficData);
              console.log(`Successfully added traffic data for week ${weekRange.weekId} to ${CSV_FILE}`);
              
              // Set outputs using environment file (new method)
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `week_id=${weekRange.weekId}\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_clones=${totalOrgClones}\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_views=${totalOrgViews}\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `repos_with_traffic=${reposWithTraffic}\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=false\n`);
            } else {
              console.log('No traffic data found');
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `week_id=${weekRange.weekId}\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_clones=0\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `total_views=0\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `repos_with_traffic=0\n`);
              fs.appendFileSync(process.env.GITHUB_OUTPUT, `skipped=false\n`);
            }
            
          } catch (error) {
            console.error('Error:', error);
            process.exit(1);
          }
        }

        main();
        EOF
        
    - name: Run traffic tracking
      id: track
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: node track-downloads.js
      
    - name: Commit and push changes
      if: steps.track.outputs.skipped != 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        if [[ -n $(git status --porcelain) ]]; then
          git add downloads.csv
          git commit -m "📊 Weekly traffic tracking: ${{ steps.track.outputs.week_id }} - ${{ steps.track.outputs.total_clones }} clones, ${{ steps.track.outputs.total_views }} views across ${{ steps.track.outputs.repos_with_traffic }} repos"
          git push
          echo "Changes committed and pushed"
        else
          echo "No changes to commit"
        fi
        
    - name: Skip notification
      if: steps.track.outputs.skipped == 'true'
      run: echo "Skipped - data for this week already exists"
        
    - name: Upload CSV as artifact
      uses: actions/upload-artifact@v4
      with:
        name: weekly-traffic-csv
        path: downloads.csv
        retention-days: 90